{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange'>Trabajo práctico N° 3</font>\n",
    "## <font color='cornflowerblue'>Visión por computadora I</font>\n",
    "### <font color='violet'>Alumno: Zenklusen, Kevin</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar el logotipo de la gaseosa dentro de las imágenes provistas en \n",
    "Material_TPs/TP3/images a partir del template Material_TPs/TP3/template\n",
    "1. (4 puntos) Obtener una detección del logo en cada imagen sin falsos positivos\n",
    "2. (4 puntos) Plantear y validar un algoritmo para múltiples detecciones en la imagen\n",
    "coca_multi.png con el mismo témplate del ítem 1\n",
    "3. (2 puntos) Generalizar el algoritmo del item 2 para todas las imágenes.\n",
    "Visualizar los resultados con bounding boxes en cada imagen mostrando el nivel de confianza\n",
    "de la detección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. El siguiente código permite detectar la ubicación del logo una vez en la imagen. En el caso de múltiples logos, indica la mejor región en la que se encuentra el conjunto.\n",
    "<br>\n",
    "Para realizar la detección se se preprocesa las imágenes quitando el ruido y utilizando el algoritmo Canny. Luego se escala y rota levemente el template para buscar los matches.\n",
    "<br>\n",
    "Esta función pretende ser un método básico de detección, y la filtración de falsos positivos se realiza mediante score.\n",
    "<br>\n",
    "El score se calcula mediante una comparación entre el template consigo mismo. Se consideró utilizar los métodos de búscqueda nomralizados (como TM_CCOEFF_NORM), pero se obtenían peores detecciones.\n",
    "<br>\n",
    "Los resultados se muestran en la carpeta output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output guardado en: images\\output\\output_COCA-COLA-LOGO.jpg con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_logo_1.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_logo_2.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_multi.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_retro_1.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_retro_2.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_logo_1.png con los 1 mejores matches\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def remove_noise(image):\n",
    "    denoised_image = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return denoised_image\n",
    "\n",
    "def calculate_self_similarity(template, edge_thresh1, edge_thresh2):\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_template = remove_noise(gray_template)\n",
    "    edges_template = cv2.Canny(gray_template, edge_thresh1, edge_thresh2)\n",
    "    result = cv2.matchTemplate(edges_template, edges_template, cv2.TM_CCORR)\n",
    "    _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "    return max_val\n",
    "\n",
    "def multi_scale_template_matching(image, template, scale_range, angle_range, edge_thresh1, edge_thresh2, n_best_matches=1, self_similarity=None):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_image = remove_noise(gray_image)\n",
    "    gray_template = remove_noise(gray_template)\n",
    "\n",
    "    image_height, image_width = gray_image.shape\n",
    "    template_height, template_width = gray_template.shape\n",
    "    scale_width = image_width / template_width\n",
    "    scale_height = image_height / template_height\n",
    "    scale_factor = min(scale_width, scale_height)\n",
    "    gray_template = cv2.resize(gray_template, (int(template_width * scale_factor), int(template_height * scale_factor)))\n",
    "\n",
    "    gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    edges_image = cv2.Canny(gray_image, edge_thresh1, edge_thresh2)    \n",
    "\n",
    "    best_matches = []\n",
    "\n",
    "    for scale in scale_range:\n",
    "        resized_template = cv2.resize(gray_template, (int(gray_template.shape[1] * scale), int(gray_template.shape[0] * scale)))\n",
    "\n",
    "        if resized_template.shape[0] > gray_image.shape[0] or resized_template.shape[1] > gray_image.shape[1]:\n",
    "            continue\n",
    "        \n",
    "        for angle in angle_range:\n",
    "            rotated_template = rotate_image(resized_template, angle)\n",
    "            rotated_template = cv2.GaussianBlur(rotated_template, (5, 5), 0)\n",
    "            edges_template = cv2.Canny(rotated_template, edge_thresh1, edge_thresh2)\n",
    "            result = cv2.matchTemplate(edges_image, edges_template, cv2.TM_CCOEFF)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "            similarity_score = (max_val / self_similarity) * 100\n",
    "\n",
    "            if len(best_matches) < n_best_matches:\n",
    "                best_matches.append((max_val, max_loc, scale, angle, rotated_template, similarity_score))\n",
    "                best_matches.sort(reverse=True, key=lambda x: x[0])\n",
    "            elif max_val > best_matches[-1][0]:\n",
    "                best_matches[-1] = (max_val, max_loc, scale, angle, rotated_template, similarity_score)\n",
    "                best_matches.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    if not best_matches:\n",
    "        print(\"No se encontraron buenos matches.\")\n",
    "        return []\n",
    "\n",
    "    return best_matches\n",
    "\n",
    "# Directorio que contiene las imágenes\n",
    "image_directory = 'images'\n",
    "template = cv2.imread('template/pattern.png', cv2.IMREAD_COLOR)\n",
    "scale_range = np.linspace(0.02, 1, 100)\n",
    "angle_range = range(-2, 3)  # De -2 a 2 grados\n",
    "edge_thresh1 = 100\n",
    "edge_thresh2 = 200\n",
    "n_best_matches = 1  # Número de mejores matches que queremos graficar\n",
    "match_score = 5.0 # Umbral de detección\n",
    "\n",
    "output_directory = os.path.join(image_directory, 'output')\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Calcular la similitud del template consigo mismo\n",
    "self_similarity = calculate_self_similarity(template, edge_thresh1, edge_thresh2)\n",
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        best_matches = multi_scale_template_matching(image, template, scale_range, angle_range, edge_thresh1, edge_thresh2, n_best_matches, self_similarity)\n",
    "        \n",
    "        if best_matches:\n",
    "            for i, (val, loc, scale, angle, match_template, score) in enumerate(best_matches):\n",
    "                if score > match_score:\n",
    "                    top_left = loc\n",
    "                    template_height, template_width = match_template.shape\n",
    "                    bottom_right = (top_left[0] + template_width, top_left[1] + template_height)\n",
    "                    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "                    cv2.putText(image, f'Match {i+1}: {score:.2f}%', (top_left[0], top_left[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            output_path = os.path.join(output_directory, 'output_' + filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "            print(f'Output guardado en: {output_path} con los {n_best_matches} mejores matches')\n",
    "        else:\n",
    "            print(f'No se encontró un buen match para la imagen: {filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. El siguiente código permite detectar las múltiples ocurrencias del logo. Se utiliza otro método de detección, lo que permite individualizar las ocurrencias cuando el umbral está correctamente seteado. \n",
    "Se utiliza un algoritmo similar al del punto 1, con detector de bordes y escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Leer la imagen principal y el template\n",
    "img_rgb = cv.imread('images/coca_multi.png')\n",
    "assert img_rgb is not None, \"El archivo no pudo ser leído, verifica con os.path.exists()\"\n",
    "img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "template = cv.imread('template/pattern.png', cv.IMREAD_GRAYSCALE)\n",
    "assert template is not None, \"El archivo no pudo ser leído, verifica con os.path.exists()\"\n",
    "\n",
    "# Definir el rango de escalas a probar\n",
    "scales = np.linspace(0.2, 1.0, 100)\n",
    "\n",
    "# Inicializar una lista para almacenar los puntos encontrados\n",
    "all_points = []\n",
    "\n",
    "def remove_noise(image):\n",
    "    # Aplicar un filtro bilateral para eliminar el ruido\n",
    "    denoised_image = cv.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return denoised_image\n",
    "\n",
    "template = remove_noise(template)\n",
    "\n",
    "img_gray = cv.GaussianBlur(img_gray, (5, 5), 0)\n",
    "#template = cv.GaussianBlur(template, (5, 5), 0)\n",
    "img_gray = cv.Canny(img_gray, 150, 200)\n",
    "template = cv.Canny(template, 150, 200)\n",
    "\n",
    "# Iterar sobre las diferentes escalas\n",
    "for scale in scales:\n",
    "    # Redimensionar el template según la escala actual\n",
    "    width = int(template.shape[1] * scale)\n",
    "    height = int(template.shape[0] * scale)\n",
    "    resized_template = cv.resize(template, (width, height))\n",
    "    \n",
    "    # Realizar la búsqueda del template en la imagen\n",
    "    res = cv.matchTemplate(img_gray, resized_template, cv.TM_CCORR_NORMED)\n",
    "    threshold = 0.245\n",
    "    loc = np.where(res >= threshold)\n",
    "    \n",
    "    # Almacenar los puntos encontrados\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        all_points.append((pt[0], pt[1], pt[0] + width, pt[1] + height, res[pt[1], pt[0]]))\n",
    "\n",
    "# Aplicar Non-Maximum Suppression (NMS)\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    score = boxes[:,4]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(score)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "boxes = np.array(all_points)\n",
    "picked_boxes = non_max_suppression(boxes, 0.3)\n",
    "\n",
    "# Dibujar los rectángulos en la imagen original\n",
    "for (x1, y1, x2, y2, _) in picked_boxes:\n",
    "    cv.rectangle(img_rgb, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "# Guardar la imagen con los resultados\n",
    "cv.imwrite('Multi_detect.png', img_rgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Método \"generalizado\" combina los métodos de los puntos 1 y 2. Primero se intenta con el método del punto 2 y, en caso de no detectar nada, pasa a usar el método del punto 1, lo que logra detectar el logo en todas las imágenes provistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output guardado en: images\\output\\output_COCA-COLA-LOGO.jpg con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_logo_1.png\n",
      "Output guardado en: images\\output\\output_coca_logo_2.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_multi.png\n",
      "Output guardado en: images\\output\\output_coca_retro_1.png con los 1 mejores matches\n",
      "Output guardado en: images\\output\\output_coca_retro_2.png\n",
      "Output guardado en: images\\output\\output_logo_1.png con los 1 mejores matches\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def remove_noise(image):\n",
    "    denoised_image = cv.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return denoised_image\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def calculate_self_similarity(template, edge_thresh1, edge_thresh2):\n",
    "    gray_template = cv.cvtColor(template, cv.COLOR_BGR2GRAY)\n",
    "    gray_template = remove_noise(gray_template)\n",
    "    edges_template = cv.Canny(gray_template, edge_thresh1, edge_thresh2)\n",
    "    result = cv.matchTemplate(edges_template, edges_template, cv.TM_CCORR)\n",
    "    _, max_val, _, _ = cv.minMaxLoc(result)\n",
    "    return max_val\n",
    "\n",
    "def multi_scale_template_matching(image, template, scale_range, angle_range, edge_thresh1, edge_thresh2, n_best_matches=1, self_similarity=None):\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    gray_template = cv.cvtColor(template, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_image = remove_noise(gray_image)\n",
    "    gray_template = remove_noise(gray_template)\n",
    "\n",
    "    image_height, image_width = gray_image.shape\n",
    "    template_height, template_width = gray_template.shape\n",
    "    scale_width = image_width / template_width\n",
    "    scale_height = image_height / template_height\n",
    "    scale_factor = min(scale_width, scale_height)\n",
    "    gray_template = cv.resize(gray_template, (int(template_width * scale_factor), int(template_height * scale_factor)))\n",
    "\n",
    "    gray_image = cv.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    edges_image = cv.Canny(gray_image, edge_thresh1, edge_thresh2)\n",
    "\n",
    "    best_matches = []\n",
    "\n",
    "    for scale in scale_range:\n",
    "        resized_template = cv.resize(gray_template, (int(gray_template.shape[1] * scale), int(gray_template.shape[0] * scale)))\n",
    "\n",
    "        if resized_template.shape[0] > gray_image.shape[0] or resized_template.shape[1] > gray_image.shape[1]:\n",
    "            continue\n",
    "\n",
    "        for angle in angle_range:\n",
    "            rotated_template = rotate_image(resized_template, angle)\n",
    "            rotated_template = cv.GaussianBlur(rotated_template, (5, 5), 0)\n",
    "            edges_template = cv.Canny(rotated_template, edge_thresh1, edge_thresh2)\n",
    "            result = cv.matchTemplate(edges_image, edges_template, cv.TM_CCOEFF)\n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "\n",
    "            similarity_score = (max_val / self_similarity) * 100\n",
    "\n",
    "            if len(best_matches) < n_best_matches:\n",
    "                best_matches.append((max_val, max_loc, scale, angle, rotated_template, similarity_score))\n",
    "                best_matches.sort(reverse=True, key=lambda x: x[0])\n",
    "            elif max_val > best_matches[-1][0]:\n",
    "                best_matches[-1] = (max_val, max_loc, scale, angle, rotated_template, similarity_score)\n",
    "                best_matches.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    if not best_matches:\n",
    "        print(\"No se encontraron buenos matches.\")\n",
    "        return []\n",
    "\n",
    "    return best_matches\n",
    "\n",
    "def process_images(image_directory, template_path):\n",
    "    scales = np.linspace(0.2, 1.0, 100)\n",
    "    edge_thresh1 = 100\n",
    "    edge_thresh2 = 200\n",
    "    n_best_matches = 1\n",
    "    match_score = 5.0\n",
    "    angle_range = range(-2, 3)\n",
    "    template = cv.imread(template_path, cv.IMREAD_GRAYSCALE)\n",
    "    assert template is not None, \"El archivo no pudo ser leído, verifica con os.path.exists()\"\n",
    "    template = remove_noise(template)\n",
    "\n",
    "    self_similarity = calculate_self_similarity(cv.imread(template_path, cv.IMREAD_COLOR), edge_thresh1, edge_thresh2)\n",
    "    \n",
    "    output_directory = os.path.join(image_directory, 'output')\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(image_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "            img_rgb = cv.imread(image_path, cv.IMREAD_COLOR)\n",
    "            assert img_rgb is not None, \"El archivo no pudo ser leído, verifica con os.path.exists()\"\n",
    "            img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "            img_gray = cv.GaussianBlur(img_gray, (5, 5), 0)\n",
    "            img_gray = cv.Canny(img_gray, 150, 200)\n",
    "            template_edges = cv.Canny(template, 150, 200)\n",
    "            \n",
    "            all_points = []\n",
    "            \n",
    "            for scale in scales:\n",
    "                width = int(template_edges.shape[1] * scale)\n",
    "                height = int(template_edges.shape[0] * scale)\n",
    "                \n",
    "                if width > img_gray.shape[1] or height > img_gray.shape[0]:\n",
    "                    continue\n",
    "                \n",
    "                resized_template = cv.resize(template_edges, (width, height))\n",
    "                \n",
    "                res = cv.matchTemplate(img_gray, resized_template, cv.TM_CCORR_NORMED)\n",
    "                threshold = 0.27\n",
    "                loc = np.where(res >= threshold)                \n",
    "                \n",
    "                for pt in zip(*loc[::-1]):\n",
    "                    all_points.append((pt[0], pt[1], pt[0] + width, pt[1] + height, res[pt[1], pt[0]]))\n",
    "            \n",
    "            if all_points:\n",
    "                boxes = np.array(all_points)\n",
    "                picked_boxes = non_max_suppression(boxes, 0.3)\n",
    "                \n",
    "                for (x1, y1, x2, y2, score) in picked_boxes:\n",
    "                    cv.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "                    cv.putText(img_rgb, f'{score:.2f}', (x1, y1 - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)\n",
    "                \n",
    "                output_path = os.path.join(output_directory, 'output_' + filename)\n",
    "                cv.imwrite(output_path, img_rgb)\n",
    "                print(f'Output guardado en: {output_path}')\n",
    "            else:\n",
    "                image = cv.imread(image_path, cv.IMREAD_COLOR)\n",
    "                template_color = cv.imread(template_path, cv.IMREAD_COLOR)\n",
    "                best_matches = multi_scale_template_matching(image, template_color, np.linspace(0.02, 1, 100), angle_range, edge_thresh1, edge_thresh2, n_best_matches, self_similarity)\n",
    "                \n",
    "                if best_matches:\n",
    "                    for i, (val, loc, scale, angle, match_template, score) in enumerate(best_matches):\n",
    "                        if score > match_score:\n",
    "                            top_left = loc\n",
    "                            template_height, template_width = match_template.shape\n",
    "                            bottom_right = (top_left[0] + template_width, top_left[1] + template_height)\n",
    "                            cv.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "                            cv.putText(image, f'Match {i+1}: {score:.2f}%', (top_left[0], top_left[1]-10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                    \n",
    "                    output_path = os.path.join(output_directory, 'output_' + filename)\n",
    "                    cv.imwrite(output_path, image)\n",
    "                    print(f'Output guardado en: {output_path} con los {n_best_matches} mejores matches')\n",
    "                else:\n",
    "                    print(f'No se encontró un buen match para la imagen: {filename}')\n",
    "\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    score = boxes[:, 4]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(score)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "# Directorio que contiene las imágenes y ruta del template\n",
    "image_directory = 'images'\n",
    "template_path = 'template/pattern.png'\n",
    "\n",
    "process_images(image_directory, template_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
